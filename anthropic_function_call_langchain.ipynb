{"cells":[{"cell_type":"code","execution_count":7,"metadata":{"id":"783OkDFCiZHf"},"outputs":[],"source":["from langchain.chat_models import BedrockChat\n","from langchain.schema import HumanMessage\n","from langchain.tools import YouTubeSearchTool\n","from langchain.agents import load_tools\n","import os\n","import boto3\n","\n","# os.environ['AWS_ACCESS_KEY_ID'] = \"\"\n","# os.environ['AWS_SECRET_ACCESS_KEY'] = \"\"\n","\n","BEDROCK_CLIENT = boto3.client(\"bedrock-runtime\", 'us-east-1')\n","\n","llm = BedrockChat(model_id=\"anthropic.claude-v2:1\", model_kwargs={\"temperature\": 0}, client=BEDROCK_CLIENT)\n","\n","tools = [YouTubeSearchTool()]\n","\n","#tools = load_tools([\"requests_all\"])"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"py7Lkb6uttoY"},"outputs":[],"source":["prompt_template = \"\"\"\n","You are a helfull assistant, your task is help the user achieve is goal.\n","In this environment you have access to a set of tools you can use to answer the user's question.\n","Use them in a smart way to fullfill our objetives. Always consider the history of previous steps to ensure a continuos progress towards the objetive.\n","When you have the answer for the user, always answer it in this forma bellow:\n","Final Answer: answer to user\n","\n","\n","You may call them like this. Only invoke one function at a time and wait for the results before invoking another function:\n","<function_calls>\n","<invoke>\n","<tool_name>$TOOL_NAME</tool_name>\n","<parameters>\n","<$PARAMETER_NAME>$PARAMETER_VALUE</$PARAMETER_NAME>\n","...\n","</parameters>\n","</invoke>\n","</function_calls>\n","\n","Here are the tools available:\n","<tools>\n","{tools_string}\n","</tools>\n","\n","\n","User:\n","{input}\n","\n","\"\"\""]},{"cell_type":"markdown","metadata":{"id":"c01uDTldth4v"},"source":[]},{"cell_type":"code","execution_count":9,"metadata":{"id":"OlkmuIP5in0E"},"outputs":[],"source":["from langchain_core.tools import BaseTool\n","\n","from langchain_community.utils.openai_functions import (\n","    FunctionDescription,\n","    ToolDescription,\n","    convert_pydantic_to_openai_function,\n",")\n","\n","def format_tool_to_anthropic_function(tool: BaseTool) -> FunctionDescription:\n","\t\"\"\"Format tool into the Anthropic function API.\"\"\"\n","\tnew_tool = f\"\"\"\n","<tool_description>\n","<tool_name>{tool.name}</tool_name>\n","<description>\n","{tool.description}\n","<parameters>\n","<parameter>\n","<name>__arg1</name>\n","<type>string</type>\n","<description>The input of the function</description>\n","</parameter>\n","</parameters>\"\"\"\n","\treturn new_tool"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"ah-cwBFikg10"},"outputs":[],"source":["import json\n","from json import JSONDecodeError\n","from typing import List, Union\n","\n","import xml.etree.ElementTree as ET\n","\n","from langchain_core.agents import AgentAction, AgentActionMessageLog, AgentFinish\n","from langchain_core.exceptions import OutputParserException\n","from langchain_core.messages import (\n","    AIMessage,\n","    BaseMessage,\n",")\n","from langchain_core.outputs import ChatGeneration, Generation\n","\n","from langchain.agents.agent import AgentOutputParser\n","\n","\n","class AnthropicFunctionsAgentOutputParser(AgentOutputParser):\n","\n","    @staticmethod\n","    def _extract_function_call(full_text):\n","        # Encontrar o início e o fim da string XML\n","        if \"function_calls\" not in full_text:\n","            return None\n","\n","        start = full_text.find(\"<function_calls>\")\n","        end = full_text.find(\"</function_calls>\") + len(\"</function_calls>\")\n","\n","        # Extrair a string XML\n","        xml_string = full_text[start:end]\n","\n","        # Análise da string XML\n","        root = ET.fromstring(xml_string)\n","\n","        # Encontrar o nome da ferramenta\n","        tool_name = root.find(\".//tool_name\").text\n","\n","        # Construir o dicionário de parâmetros\n","        parameters = {}\n","        for param in root.findall(\".//parameters/*\"):\n","            parameters[param.tag] = param.text\n","\n","        # Construir o dicionário final com nome e parâmetros\n","        return {\n","            \"name\": tool_name,\n","            \"arguments\": parameters\n","        }\n","\n","    @property\n","    def _type(self) -> str:\n","        return \"openai-functions-agent\"\n","\n","    @staticmethod\n","    def _parse_ai_message(message: BaseMessage) -> Union[AgentAction, AgentFinish]:\n","        \"\"\"Parse an AI message.\"\"\"\n","        if not isinstance(message, AIMessage):\n","            raise TypeError(f\"Expected an AI message got {type(message)}\")\n","\n","        function_call = AnthropicFunctionsAgentOutputParser._extract_function_call(message.content)\n","\n","        if function_call and 'Final Answer:' not in message.content:\n","            function_name = function_call[\"name\"]\n","            try:\n","                if len(function_call.keys()) == 0:\n","                    # OpenAI returns an empty string for functions containing no args\n","                    _tool_input = {}\n","                else:\n","                    # otherwise it returns a json object\n","                    _tool_input = function_call[\"arguments\"]\n","            except JSONDecodeError:\n","                raise OutputParserException(\n","                    f\"Could not parse tool input: {function_call} because \"\n","                    f\"the `arguments` is not valid JSON.\"\n","                )\n","\n","            if \"__arg1\" in _tool_input.keys():\n","                tool_input = _tool_input[\"__arg1\"]\n","            else:\n","                tool_input = _tool_input\n","\n","            content_msg = f\"responded: {message.content}\\n\" if message.content else \"\\n\"\n","            log = f\"\\nInvoking: `{function_name}` with `{tool_input}`\\n{content_msg}\\n\"\n","            return AgentActionMessageLog(\n","                tool=function_name,\n","                tool_input=tool_input,\n","                log=log,\n","                message_log=[message],\n","            )\n","\n","        start = message.content.find(\"<function_calls>\")\n","\n","        return AgentFinish(\n","            return_values={\"output\": message.content[start:]}, log=str(message.content)\n","        )\n","\n","    def parse_result(\n","            self, result: List[Generation], *, partial: bool = False\n","        ) -> Union[AgentAction, AgentFinish]:\n","            if not isinstance(result[0], ChatGeneration):\n","                raise ValueError(\"This output parser only works on ChatGeneration output\")\n","            message = result[0].message\n","            return self._parse_ai_message(message)\n","\n","\n","    def parse(self, text: str) -> Union[AgentAction, AgentFinish]:\n","        raise ValueError(\"Can only parse messages\")\n"]},{"cell_type":"code","execution_count":11,"metadata":{"id":"s52od1pJEIZP"},"outputs":[],"source":["import json\n","from typing import List, Sequence, Tuple\n","\n","from langchain_core.agents import AgentAction, AgentActionMessageLog\n","from langchain_core.messages import AIMessage, BaseMessage, FunctionMessage\n","\n","def _convert_agent_action_to_messages(agent_action: AgentAction, observation: str) -> List[BaseMessage]:\n","    \"\"\"Convert an agent action to a message.\n","\n","    This code is used to reconstruct the original AI message from the agent action.\n","\n","    Args:\n","        agent_action: Agent action to convert.\n","\n","    Returns:\n","        AIMessage that corresponds to the original tool invocation.\n","    \"\"\"\n","    if isinstance(agent_action, AgentActionMessageLog):\n","        return str(list(agent_action.message_log) + [_create_function_message(agent_action, observation)])\n","    else:\n","        return agent_action.log\n","\n","def _create_function_message(agent_action: AgentAction, observation: str) -> FunctionMessage:\n","    \"\"\"Convert agent action and observation into a function message.\n","    Args:\n","        agent_action: the tool invocation request from the agent\n","        observation: the result of the tool invocation\n","    Returns:\n","        FunctionMessage that corresponds to the original tool invocation\n","    \"\"\"\n","    if not isinstance(observation, str):\n","        try:\n","            content = json.dumps(observation, ensure_ascii=False)\n","        except Exception:\n","            content = str(observation)\n","    else:\n","        content = observation\n","    return agent_action.tool+\":\"+content\n","\n","\n","def format_to_openai_function_messages(intermediate_steps: Sequence[Tuple[AgentAction, str]]) -> List[BaseMessage]:\n","    \"\"\"Convert (AgentAction, tool output) tuples into FunctionMessages.\n","\n","    Args:\n","        intermediate_steps: Steps the LLM has taken to date, along with observations\n","\n","    Returns:\n","        list of messages to send to the LLM for the next prediction\n","    \"\"\"\n","    messages = \"\"\n","\n","    for agent_action, observation in intermediate_steps:\n","        messages.extend(_convert_agent_action_to_messages(agent_action, observation))\n","\n","    return messages\n"]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11430,"status":"ok","timestamp":1704477256496,"user":{"displayName":"Danielle Franca","userId":"16714923616961580785"},"user_tz":180},"id":"n2rX_ioZj24x","outputId":"42e8e400-b119-43dd-d963-3181439a38ee"},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","\n","\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[32;1m\u001b[1;3m\n","Invoking: `youtube_search` with `AGI, 5`\n","responded:  <function_calls>\n","<invoke>\n","<tool_name>youtube_search</tool_name>\n","<parameters>\n","<__arg1>AGI, 5</__arg1>\n","</parameters>\n","</invoke>\n","</function_calls>\n","\n","\u001b[0m\u001b[36;1m\u001b[1;3m['https://www.youtube.com/watch?v=2gc3ZnZTY8E&pp=ygUDQUdJ', 'https://www.youtube.com/watch?v=D1nc80yMWqA&pp=ygUDQUdJ', 'https://www.youtube.com/watch?v=JUX24r36OLU&pp=ygUDQUdJ', 'https://www.youtube.com/watch?v=ICgjWMZp88U&pp=ygUDQUdJ', 'https://www.youtube.com/watch?v=tPul4xH2GAo&pp=ygUDQUdJ']\u001b[0m\u001b[32;1m\u001b[1;3m\n","Invoking: `youtube_search` with `AGI, 5`\n","responded:  <function_calls>\n","<invoke>\n","<tool_name>youtube_search</tool_name>\n","<parameters>\n","<__arg1>AGI, 5</__arg1>\n","</parameters>\n","</invoke>\n","</function_calls>\n","\n","\u001b[0m\u001b[36;1m\u001b[1;3m['https://www.youtube.com/watch?v=2gc3ZnZTY8E&pp=ygUDQUdJ', 'https://www.youtube.com/watch?v=D1nc80yMWqA&pp=ygUDQUdJ', 'https://www.youtube.com/watch?v=JUX24r36OLU&pp=ygUDQUdJ', 'https://www.youtube.com/watch?v=ICgjWMZp88U&pp=ygUDQUdJ', 'https://www.youtube.com/watch?v=tPul4xH2GAo&pp=ygUDQUdJ']\u001b[0m\u001b[32;1m\u001b[1;3m <function_calls>\n","<invoke>\n","<tool_name>youtube_search</tool_name>\n","<parameters>\n","<__arg1>AGI, 5</__arg1>\n","</parameters>\n","</invoke>\n","</function_calls>\n","\n","Final Answer: ['https://www.youtube.com/watch?v=2gc3ZnZTY8E&pp=ygUDQUdJ', 'https://www.youtube.com/watch?v=D1nc80yMWqA&pp=ygUDQUdJ', 'https://www.youtube.com/watch?v=JUX24r36OLU&pp=ygUDQUdJ', 'https://www.youtube.com/watch?v=ICgjWMZp88U&pp=ygUDQUdJ', 'https://www.youtube.com/watch?v=tPul4xH2GAo&pp=ygUDQUdJ']\u001b[0m\n","\n","\u001b[1m> Finished chain.\u001b[0m\n"]},{"data":{"text/plain":["{'input': 'List 5 youtube videos that talk about AGI usando a tool disponível',\n"," 'tools_string': '<tools><tools>\\n<tool_description>\\n<tool_name>youtube_search</tool_name>\\n<description>\\nsearch for youtube videos associated with a person. the input to this tool should be a comma separated list, the first part contains a person name and the second a number that is the maximum number of video results to return aka num_results. the second part is optional\\n<parameters>\\n<parameter>\\n<name>__arg1</name>\\n<type>string</type>\\n<description>The input of the function</description>\\n</parameter>\\n</parameters></tools></tools>',\n"," 'output': \"<function_calls>\\n<invoke>\\n<tool_name>youtube_search</tool_name>\\n<parameters>\\n<__arg1>AGI, 5</__arg1>\\n</parameters>\\n</invoke>\\n</function_calls>\\n\\nFinal Answer: ['https://www.youtube.com/watch?v=2gc3ZnZTY8E&pp=ygUDQUdJ', 'https://www.youtube.com/watch?v=D1nc80yMWqA&pp=ygUDQUdJ', 'https://www.youtube.com/watch?v=JUX24r36OLU&pp=ygUDQUdJ', 'https://www.youtube.com/watch?v=ICgjWMZp88U&pp=ygUDQUdJ', 'https://www.youtube.com/watch?v=tPul4xH2GAo&pp=ygUDQUdJ']\"}"]},"execution_count":12,"metadata":{},"output_type":"execute_result"}],"source":["from langchain_core.runnables import Runnable, RunnablePassthrough\n","from langchain.agents.format_scratchpad.openai_functions import (\n","    format_to_openai_function_messages,\n",")\n","from langchain.prompts import ChatPromptTemplate, MessagesPlaceholder\n","from langchain.agents import AgentExecutor\n","\n","prompt = ChatPromptTemplate.from_messages(\n","    [\n","        (\"human\", prompt_template+ \"History: {agent_scratchpad}\"),\n","\n","    ]\n",")\n","\n","\n","agent = (\n","    RunnablePassthrough.assign(\n","        agent_scratchpad=lambda x: format_to_openai_function_messages(\n","            x[\"intermediate_steps\"]\n","        )\n","    )\n","    | prompt\n","    | llm\n","    | AnthropicFunctionsAgentOutputParser()\n",")\n","\n","chain = prompt | llm.bind(stop_sequences=['Final Answer:'])\n","\n","tools_string = \"<tools>\"+\"\".join([format_tool_to_anthropic_function(t) for t in tools])+\"</tools>\"\n","\n","agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)\n","agent_executor.invoke({\"input\":\"List 5 youtube videos that talk about AGI usando a tool disponível\", \"tools_string\":f\"<tools>{tools_string}</tools>\"})"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vaEMbfP46mTq"},"outputs":[],"source":[]}],"metadata":{"colab":{"provenance":[{"file_id":"168VFFTIoh0_mejMGzfKSn-huI3OJdq4C","timestamp":1708344156827},{"file_id":"147WAqREl4PLMihd0XP8XRubh6QUXDtUR","timestamp":1704481454659}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.1"}},"nbformat":4,"nbformat_minor":0}
