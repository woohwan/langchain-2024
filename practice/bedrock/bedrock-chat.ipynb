{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------------------\n",
    "# Setting up Amazon Bedrock with LangChain ü¶úÔ∏èüîó\n",
    "\n",
    "import boto3\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_community.chat_models import BedrockChat\n",
    "\n",
    "bedrock_runtime = boto3.client(\n",
    "    service_name=\"bedrock-runtime\",\n",
    "    region_name=\"us-east-1\",\n",
    ")\n",
    "\n",
    "model_id = \"anthropic.claude-3-sonnet-20240229-v1:0\"\n",
    "\n",
    "model_kwargs =  { \n",
    "    \"max_tokens\": 2048,\n",
    "    \"temperature\": 0.0,\n",
    "    \"top_k\": 250,\n",
    "    \"top_p\": 1,\n",
    "    \"stop_sequences\": [\"\\n\\nHuman\"],\n",
    "}\n",
    "\n",
    "model = BedrockChat(\n",
    "    client=bedrock_runtime,\n",
    "    model_id=model_id,\n",
    "    model_kwargs=model_kwargs,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here's a silly joke for you:\n",
      "\n",
      "Why did the tomato turn red? Because it saw the salad dressing!\n"
     ]
    }
   ],
   "source": [
    "# Invoke Example\n",
    "messages = [\n",
    "    (\"system\", \"You are a helpful assistant.\"),\n",
    "    (\"human\", \"{question}\"),\n",
    "]\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(messages)\n",
    "\n",
    "chain = prompt | model | StrOutputParser()\n",
    "\n",
    "# Chain Invoke\n",
    "response = chain.invoke({\"question\": \"tell me a joke\"})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ï†ÄÎäî ÌïúÍµ≠ Î∞îÎπÑÌÅêÎ•º Ï†ïÎßê Ï¢ãÏïÑÌï©ÎãàÎã§.Here are some of the most famous tourist attractions in Seoul, South Korea:\n",
      "\n",
      "1. Gyeongbokgung Palace\n",
      "2. Changdeokgung Palace\n",
      "3. Bukchon Hanok Village\n",
      "4. N Seoul Tower\n",
      "5. Myeongdong Shopping District\n",
      "6. Insadong Cultural Street\n",
      "7. Lotte World Tower\n",
      "8. Cheonggyecheon Stream\n",
      "9. Dongdaemun Design Plaza\n",
      "10. Jogyesa Buddhist Temple\n",
      "11. Namdaemun Market\n",
      "12. Gwanghwamun Square\n",
      "13. Deoksugung Palace\n",
      "14. Bongeunsa Temple\n",
      "15. Banpo Bridge Rainbow Fountain\n",
      "16. Seoul City Wall\n",
      "17. Leeum Samsung Museum of Art\n",
      "18. National Museum of Korea\n",
      "19. Hongdae Street\n",
      "20. Ihwa Mural Village\n",
      "\n",
      "These attractions offer a mix of historical palaces, traditional neighborhoods, modern architecture, shopping districts, cultural sites, and natural landmarks, showcasing the rich heritage and vibrant modernity of Seoul."
     ]
    }
   ],
   "source": [
    "# Stream - Example 1\n",
    "system_message = \"You are a helpful assistant that translates {input_language} to {output_language}.\"\n",
    "human_message = \"{text}\"\n",
    "\n",
    "messages = [\n",
    "    (\"system\", system_message),\n",
    "    (\"human\", human_message)\n",
    "]\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(messages)\n",
    "\n",
    "chain = prompt | model | StrOutputParser()\n",
    "\n",
    "for chunk in chain.stream(\n",
    "    {\n",
    "        \"input_language\": \"English\",\n",
    "        \"output_language\": \"Korean\",\n",
    "        \"text\": \"I love Korean BBQ\",\n",
    "    }\n",
    "):\n",
    "    print(chunk, end=\"\", flush=True)\n",
    "\n",
    "# Stream - Example 2\n",
    "messages = [\n",
    "    (\"human\", \"Give me a list of famous tourist attractions in Seoul, Korea\")\n",
    "]\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(messages)\n",
    "\n",
    "chain = prompt | model | StrOutputParser()\n",
    "\n",
    "for chunk in chain.stream({}):\n",
    "    print(chunk, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here's a baseball joke for you:\n",
      "\n",
      "Why did the baseball player bring a ladder to the game? Because he wanted to hit a ground rule double!\n"
     ]
    }
   ],
   "source": [
    "# Ainvoke Example\n",
    "messages = [(\"human\", \"Tell me a joke about {topic}\")]\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(messages)\n",
    "\n",
    "chain = prompt | model | StrOutputParser()\n",
    "\n",
    "response = await chain.ainvoke({\"topic\": \"baseball\"})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
