{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import BedrockChat\n",
    "from langchain.schema import HumanMessage\n",
    "from langchain.tools import YouTubeSearchTool\n",
    "from langchain.agents import load_tools\n",
    "import os\n",
    "import boto3\n",
    "\n",
    "br_client = boto3.client(\"bedrock-runtime\", \"us-east-1\")\n",
    "\n",
    "llm = BedrockChat(\n",
    "    model_id=\"anthropic.claude-v2:1\",\n",
    "    client=br_client,\n",
    "    model_kwargs={\n",
    "        \"temperature\": 0\n",
    "    }\n",
    ")\n",
    "\n",
    "tools = [ YouTubeSearchTool() ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = \"\"\"\n",
    "Human:\n",
    "You are a helpful assistant, your task is help the user achive is goal.\n",
    "In this environment you have access to a set of tools you can use to answer the user's question.\n",
    "Use them in a smart way to fulfill our objective. Always consider the history of previous steps to ensure a continuous progress towards the objective.\n",
    "When you have the answer for the user, always answer it in this forma below:\n",
    "Final Answer: answer to user\n",
    "\n",
    "\n",
    "You may call them like this. Only invoke one function at a time and wait for the results before invoking another function:\n",
    "<function_calls>\n",
    "<invoke>\n",
    "<tool_name>$TOOL_NAME</tool_name>\n",
    "<parameters>\n",
    "<$PARAMETER_NAME>$PARAMETER_VALUE</$PARAMETER_NAME>\n",
    "...\n",
    "</parameters>\n",
    "</invoke>\n",
    "</function_calls>\n",
    "\n",
    "Here are the tools available:\n",
    "<tools>\n",
    "{tools_string}\n",
    "</tools>\n",
    "\n",
    "\n",
    "User:\n",
    "{input}\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FUNCTION THAT CONVERT THE TOOLS FOR THE PROMPT FORMAT\n",
    "from langchain_core.tools import BaseTool\n",
    "\n",
    "from langchain_community.utils.openai_functions import (\n",
    "    FunctionDescription,\n",
    "    ToolDescription,\n",
    "    convert_pydantic_to_openai_function\n",
    ")\n",
    "\n",
    "def format_tool_to_anthropic_function(tool: BaseTool) -> FunctionDescription:\n",
    "    \"\"\"Format tool into the Bedrock function API.\"\"\"\n",
    "    new_tool = f\"\"\"\n",
    "<tool_description>\n",
    "<tool_name>{tool.name}</tool_name>\n",
    "<description>\n",
    "{tool.description}\n",
    "<parameters>\n",
    "<parameter>\n",
    "<name>__arg1</name>\n",
    "<type>string</type>\n",
    "<description>The input of the function</description>\n",
    "</parameters>\"\"\"\n",
    "    return new_tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom parser to interpret model answer\n",
    "import json\n",
    "from json import JSONDecodeError\n",
    "from typing import List, Union\n",
    "\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "from langchain_core.agents import AgentAction, AgentActionMessageLog, AgentFinish\n",
    "from langchain_core.exceptions import OutputParserException\n",
    "from langchain_core.messages import (\n",
    "    AIMessage,\n",
    "    BaseMessage\n",
    ")\n",
    "from langchain_core.outputs import ChatGeneration, Generation\n",
    "from langchain.agents.agent import AgentOutputParser\n",
    "\n",
    "class AnthropicFunctionAgentOutputParser(AgentOutputParser):\n",
    "    @staticmethod\n",
    "    def _extract_function_call(full_text):\n",
    "        # 문자열의 시자과 끝 찾기\n",
    "        if \"function_calls\" not in full_text:\n",
    "            return None\n",
    "        \n",
    "        start = full_text.find(\"<function_calls>\")\n",
    "        end = full_text.find(\"</function_calls>\") + len(\"</function_calls>\")\n",
    "\n",
    "        # XML 문자열\n",
    "        xml_string = full_text[start:end]\n",
    "\n",
    "        # XML 문자열 분석\n",
    "        root = ET.fromstring(xml_string)\n",
    "\n",
    "        # tool name\n",
    "        tool_name = root.find(\".//tool_name\").text\n",
    "\n",
    "        # parameter\n",
    "        parameters = {}\n",
    "        for param in root.findall(\".//parameters/*\"):\n",
    "            parameters[param.tag] = param.text\n",
    "\n",
    "        return {\n",
    "            \"name\": tool_name,\n",
    "            \"arguments\": parameters\n",
    "        }\n",
    "    \n",
    "    @property\n",
    "    def _type(self) -> str:\n",
    "        return \"openai-functions-agent\"\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
