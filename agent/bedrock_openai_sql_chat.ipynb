{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- https://github.com/langchain-ai/langchain/blob/master/cookbook/LLaMA2_sql_chat.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model 인스턴스 생성\n",
    "from langchain_community.chat_models import ChatOpenAI\n",
    "llm_text = ChatOpenAI(model=\"gpt-3.5-turbo\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'프랑스의 수도는 파리입니다.'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model 기본 테스트\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# prompt = ChatPromptTemplate.from_template(\"대한민국의 수도는 어디입니까?\")\n",
    "# llm_text.invoke(prompt)\n",
    "# chain = prompt | llm_text | StrOutputParser()\n",
    "# chain.invoke({})\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(\"{country}의 수도는 어디입니까?\")\n",
    "\n",
    "chain = (\n",
    "  { \"country\": RunnablePassthrough()}\n",
    "  | prompt\n",
    "  | llm_text\n",
    "  | StrOutputParser()\n",
    ")\n",
    "\n",
    "chain.invoke(\"프랑스\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = llm_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DB\n",
    "Connect to a SQLite DB.\n",
    "- SQLDatabaseChain의  사용하지 않을 경우, SQL 생성 시 AI의 전문(preamble)이 들어가서 정상적인 Query가 수행되지 않는\n",
    "경우 있음. (특히 chat시)\n",
    "- 큰 DB는 SQLDatabaseSequenceChain \n",
    "- import 시 path 주의할 것. (계속 변경됨)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.utilities import SQLDatabase\n",
    "from langchain_experimental.sql import SQLDatabaseChain\n",
    "\n",
    "db = SQLDatabase.from_uri(\"sqlite:///nba_roster.db\", sample_rows_in_table_info=0)\n",
    "db_chain = SQLDatabaseChain.from_llm(llm, db)\n",
    "db_chain.return_sql=True\n",
    "\n",
    "def get_schema(_):\n",
    "  return db.get_table_info()\n",
    "\n",
    "def run_query(query):\n",
    "  return db_chain.run(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"SELECT Team\\nFROM nba_roster\\nWHERE NAME = 'Klay Thompson'\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prompt\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "# Update the template based on the type of SQL Database like MySQL, Microsoft SQL Server and so on\n",
    "template = \"\"\"Based on the table schema below, write a SQL query that would answer the user's question:\n",
    "{schema}\n",
    "\n",
    "Question: {question}\n",
    "SQL Query:\"\"\"\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"Given an input question, convert it to a SQL query without preamble.\"),\n",
    "        (\"human\", template),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Chain to query\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "sql_response = (\n",
    "    RunnablePassthrough.assign(schema=get_schema)\n",
    "    | prompt\n",
    "    | llm.bind(stop=[\"\\nSQLResult:\"])\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "# sql_response.invoke({\"question\": \"What team is Klay Thompson on?\"})\n",
    "sql_response.invoke({\"question\": \" Klay Thompson이 속한 팀은?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='The number of unique teams in the NBA roster table is represented by the result of the SQL query as \"Unique_Teams\".')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Chain to answer\n",
    "template = \"\"\"Based on the table schema below, question, sqlite sql query, and sqlite sql response, write a natural language response:\n",
    "{schema}\n",
    "\n",
    "Question: {question}\n",
    "SQL Query: {query}\n",
    "SQL Response: {response}\n",
    "\"\"\"\n",
    "\n",
    "prompt_response = ChatPromptTemplate.from_messages(\n",
    "  [\n",
    "    (\n",
    "      \"system\",\n",
    "      \"You're sqlite SQL Expert. Given an input question and SQL response, convert it to a natural language answer. No pre-amble\"\n",
    "    ),\n",
    "    (\"human\", template)\n",
    "  ]\n",
    ")\n",
    "\n",
    "full_chain = (\n",
    "  RunnablePassthrough.assign(query=sql_response)\n",
    "  | RunnablePassthrough.assign(\n",
    "    schema=get_schema,\n",
    "    response=lambda x: db_chain.run(x[\"query\"]),\n",
    "  )\n",
    "  | prompt_response\n",
    "  | llm\n",
    ")\n",
    "\n",
    "# full_chain.invoke({\"question\": \"How many unique teams are there?\"})\n",
    "full_chain.invoke({\"question\": \"고유한 소속팀의 수는?\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chat with a SQL DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"SELECT Team FROM nba_roster WHERE NAME = 'Klay Thompson'\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prompt\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "\n",
    "template = \"\"\"Given an input question, convert it to a SQL query only. Based on the table schema below, write a SQL query that would answer the user's question:\n",
    "{schema}\n",
    "\"\"\"\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", template),\n",
    "        MessagesPlaceholder(variable_name=\"history\"),\n",
    "        (\"human\", \"{question}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "memory = ConversationBufferMemory(return_messages=True)\n",
    "\n",
    "# Chain to query with memory\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "\n",
    "sql_chain = (\n",
    "    RunnablePassthrough.assign(\n",
    "        schema=get_schema,\n",
    "        history=RunnableLambda(lambda x: memory.load_memory_variables(x)[\"history\"]),\n",
    "    )\n",
    "    | prompt\n",
    "    | llm.bind(stop=[\"\\nSQLResult:\"])\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "\n",
    "def save(input_output):\n",
    "    output = {\"output\": input_output.pop(\"output\")}\n",
    "    memory.save_context(input_output, output)\n",
    "    return output[\"output\"]\n",
    "\n",
    "\n",
    "sql_response_memory = RunnablePassthrough.assign(output=sql_chain) | save\n",
    "# sql_response_memory.invoke({\"question\": \"What team is Klay Thompson on?\"})\n",
    "sql_response_memory.invoke({\"question\": \"Klay Thompson이 속한 팀은?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='His salary is $15,500,000.')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Chain to answer\n",
    "template = \"\"\"Based on the table schema below, question, sql query, and sql response, write a natural language response:\n",
    "{schema}\n",
    "\n",
    "\n",
    "Question: {question}\n",
    "SQL Query: {query}\n",
    "SQL Response: {response}\n",
    "\"\"\"\n",
    "prompt_response = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"Given an input question and SQL response, convert it to a natural language answer. No preamble.\",\n",
    "        ),\n",
    "        (\"human\", template),\n",
    "    ]\n",
    ")\n",
    "\n",
    "full_chain = (\n",
    "    RunnablePassthrough.assign(query=sql_response_memory)\n",
    "    | RunnablePassthrough.assign(\n",
    "        schema=get_schema,\n",
    "        response=lambda x: db_chain.run(x[\"query\"]),\n",
    "    )\n",
    "    | prompt_response\n",
    "    | llm\n",
    ")\n",
    "\n",
    "# full_chain.invoke({\"question\": \"What is his salary?\"})\n",
    "full_chain.invoke({\"question\": \"그의 월급은?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bedrock",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
