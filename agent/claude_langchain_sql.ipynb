{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "template = \"\"\"Given an table schema, use sqlite syntax to generate a sql query by choosing \n",
    "one or multiple of the following tables.\n",
    "\n",
    "For this Problem you can use the following table Schema:\n",
    "<table_schema>\n",
    "{schema}\n",
    "</table_schema\n",
    "\n",
    "Please provide the SQL query without comment for this question: \n",
    "<question>\n",
    "{question}\n",
    "</question>\n",
    "\n",
    "Wirite only query statement simply between <SQL> and </SQL> tags correspond to the above question. No preface\n",
    "SQL Query:\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.chat_models import BedrockChat\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough, RunnableLambda\n",
    "\n",
    "import boto3\n",
    "\n",
    "session = boto3.Session()\n",
    "bedrock_cli = session.client(\n",
    "  service_name='bedrock-runtime',\n",
    "  region_name='us-east-1',\n",
    "  endpoint_url=None\n",
    "  )\n",
    "\n",
    "llm = BedrockChat(\n",
    "  model_id=\"anthropic.claude-v2:1\",\n",
    "  client=bedrock_cli,\n",
    "  model_kwargs={\"temperature\": 0.1},\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.utilities import SQLDatabase\n",
    "from langchain_experimental.sql import SQLDatabaseChain\n",
    "\n",
    "db = SQLDatabase.from_uri(\"sqlite:///Chinook.db\")\n",
    "db_chain = SQLDatabaseChain.from_llm(llm, db)\n",
    "\n",
    "def get_schema(_):\n",
    "    return db.get_table_info()\n",
    "\n",
    "def run_query(query):\n",
    "    return db.run(query)\n",
    "\n",
    "# claude는 query 앞에 별도의 설명이 붙기 때문에 처리 필요\n",
    "# prompt에서 생성된 query는 <SQl></SQL> tag로 묶음.\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "def claude_query(query):\n",
    "    text = \"<root>\" + query + \"</root>\"\n",
    "    # Parsing the text as XML\n",
    "    root = ET.fromstring(text)\n",
    "    sql = root.find('SQL').text\n",
    "    return sql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sql_response = (\n",
    "    RunnablePassthrough.assign(schema=get_schema)\n",
    "    | prompt\n",
    "    | llm.bind(stop=[\"\\n\\nSQLResult\"])\n",
    "    | StrOutputParser()\n",
    "    | RunnableLambda(claude_query)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nSELECT COUNT(*) AS num_employees \\nFROM Employee\\n'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sql_response.invoke({\"question\": \"How many employees are there?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"Based on the table schema, question, sql query, and sql response, write a natural language response:\n",
    "\n",
    "{schema}\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "use only query statement between <SQL> and </SQL> tag:\n",
    "SQL Query: {query}\n",
    "SQL Response: {response}\"\"\"\n",
    "\n",
    "prompt_response = ChatPromptTemplate.from_template(template)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_chain = (\n",
    "    RunnablePassthrough.assign(query=sql_response).assign(\n",
    "        schema=get_schema,\n",
    "        response=lambda x: db.run(x[\"query\"]),\n",
    "    )\n",
    "    | prompt_response\n",
    "    | llm\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new RunnableSequence chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RunnableAssign chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RunnableParallel chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RunnableSequence chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RunnableAssign chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RunnableParallel chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RunnableLambda chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new ChatPromptTemplate chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new StrOutputParser chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RunnableLambda chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RunnableAssign chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RunnableParallel chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RunnableLambda chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RunnableLambda chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new ChatPromptTemplate chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessage(content=' <SQL>\\nSELECT COUNT(*) AS num_employees \\nFROM Employee\\n</SQL>\\n\\nThe SQL query counts the total number of rows in the Employee table. The response shows there are 8 employees.')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.callbacks import StdOutCallbackHandler\n",
    "full_chain.invoke({\"question\": \"How many employees are there?\"} )\n",
    "# full_chain.invoke({\"question\": \"How many employees are there?\"}, config={'callbacks': [StdOutCallbackHandler()]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bedrock",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
